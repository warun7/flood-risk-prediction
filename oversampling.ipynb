{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2071, 3)\n",
      "\n",
      "Class distribution before SMOTE:\n",
      "False    1570\n",
      "True      501\n",
      "Name: is_flood, dtype: int64\n",
      "\n",
      "Resampled dataset shape: (3140, 3)\n",
      "\n",
      "Class distribution after SMOTE:\n",
      "True     1570\n",
      "False    1570\n",
      "Name: is_flood, dtype: int64\n",
      "\n",
      "Saved resampled dataset to 'combined_data_smote.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('combined_data.csv')\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"\\nClass distribution before SMOTE:\")\n",
    "print(df['is_flood'].value_counts())\n",
    "\n",
    "# Prepare the features and target\n",
    "X = df[['NDVI', 'NDWI']]\n",
    "y = df['is_flood']\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(sampling_strategy='all', random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create new dataframe with SMOTE results\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=['NDVI', 'NDWI'])\n",
    "df_resampled['is_flood'] = y_resampled\n",
    "\n",
    "print(\"\\nResampled dataset shape:\", df_resampled.shape)\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(df_resampled['is_flood'].value_counts())\n",
    "\n",
    "# Save the resampled dataset\n",
    "df_resampled.to_csv('combined_data_smote.csv', index=False)\n",
    "print(\"\\nSaved resampled dataset to 'combined_data_smote.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.3.0\n",
      "Uninstalling scikit-learn-1.3.0:\n",
      "  Successfully uninstalled scikit-learn-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping imblearn as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall scikit-learn --yes\n",
    "!pip uninstall imblearn --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.2.2\n",
      "  Obtaining dependency information for scikit-learn==1.2.2 from https://files.pythonhosted.org/packages/db/98/169b46a84b48f92df2b5e163fce75d471f4df933f8b3d925a61133210776/scikit_learn-1.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.2.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (2.2.0)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-win_amd64.whl (8.3 MB)\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/8.3 MB 8.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.7/8.3 MB 8.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.2/8.3 MB 8.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.5/8.3 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.3/8.3 MB 9.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.0/8.3 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.9/8.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.8/8.3 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.7/8.3 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.7/8.3 MB 14.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.5/8.3 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.3/8.3 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.3/8.3 MB 14.7 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Obtaining dependency information for imblearn from https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: imblearn\n",
      "Successfully installed imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2071, 3)\n",
      "\n",
      "Class distribution before SMOTE:\n",
      "False    1570\n",
      "True      501\n",
      "Name: is_flood, dtype: int64\n",
      "\n",
      "Resampled dataset shape: (10000, 3)\n",
      "\n",
      "Class distribution after SMOTE:\n",
      "True     5000\n",
      "False    5000\n",
      "Name: is_flood, dtype: int64\n",
      "\n",
      "Saved resampled dataset to 'combined_data_smote_10000_scaled.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py:313: UserWarning: After over-sampling, the number of samples (5000) in class False will be larger than the number of samples in the majority class (class #False -> 1570)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py:313: UserWarning: After over-sampling, the number of samples (5000) in class True will be larger than the number of samples in the majority class (class #False -> 1570)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('combined_data.csv')\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"\\nClass distribution before SMOTE:\")\n",
    "print(df['is_flood'].value_counts())\n",
    "\n",
    "# Prepare features and target\n",
    "X = df[['NDVI', 'NDWI']]\n",
    "y = df['is_flood']\n",
    "\n",
    "# Step 1: Standardization\n",
    "standard_scaler = StandardScaler()\n",
    "X_standardized = standard_scaler.fit_transform(X)\n",
    "\n",
    "# Step 2: Normalization\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_scaled = minmax_scaler.fit_transform(X_standardized)\n",
    "\n",
    "# Step 3: SMOTE to reach 10,000 rows evenly across classes\n",
    "target_total = 10_000\n",
    "classes = y.value_counts().index.tolist()\n",
    "n_classes = len(classes)\n",
    "samples_per_class = target_total // n_classes\n",
    "\n",
    "sampling_strategy = {label: samples_per_class for label in classes}\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Step 4: Save the resampled dataset\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=['NDVI', 'NDWI'])\n",
    "df_resampled['is_flood'] = y_resampled\n",
    "\n",
    "print(\"\\nResampled dataset shape:\", df_resampled.shape)\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(df_resampled['is_flood'].value_counts())\n",
    "\n",
    "df_resampled.to_csv('combined_data_smote_10000_scaled.csv', index=False)\n",
    "print(\"\\nSaved resampled dataset to 'combined_data_smote_10000_scaled.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data (first 5 rows):\n",
      "    Latitude  Longitude  Rainfall (mm)  Temperature (°C)  Humidity (%)  \\\n",
      "0  18.861663  78.835584     218.999493         34.144337     43.912963   \n",
      "1  35.570715  77.654451      55.353599         28.778774     27.585422   \n",
      "2  29.227824  73.108463     103.991908         43.934956     30.108738   \n",
      "3  25.361096  85.610733     198.984191         21.569354     34.453690   \n",
      "4  12.524541  81.822101     144.626803         32.635692     36.292267   \n",
      "\n",
      "   River Discharge (m³/s)  Water Level (m)  Elevation (m)  Population Density  \\\n",
      "0             4236.182888         7.415552     377.465433         7276.742184   \n",
      "1             2472.585219         8.811019    7330.608875         6897.736956   \n",
      "2              977.328053         4.631799    2205.873488         4361.518494   \n",
      "3             3683.208933         2.891787    2512.277800         6163.069701   \n",
      "4             2093.390678         3.188466    2001.818223         6167.964591   \n",
      "\n",
      "   Infrastructure  Historical Floods  Flood Occurred  \n",
      "0               1                  0               1  \n",
      "1               0                  1               0  \n",
      "2               1                  1               1  \n",
      "3               1                  1               0  \n",
      "4               1                  0               0  \n",
      "\n",
      "Normalized and standardized data (first 5 rows):\n",
      "   Latitude  Longitude  Rainfall (mm)  Temperature (°C)  Humidity (%)  \\\n",
      "0  0.374639   0.373570       0.730058          0.638277      0.298909   \n",
      "1  0.950982   0.332832       0.184491          0.459386      0.094805   \n",
      "2  0.732198   0.176037       0.346643          0.964702      0.126348   \n",
      "3  0.598823   0.607250       0.663330          0.219020      0.180662   \n",
      "4  0.156053   0.476577       0.482112          0.587978      0.203646   \n",
      "\n",
      "   River Discharge (m³/s)  Water Level (m)  Elevation (m)  Population Density  \\\n",
      "0                0.847286         0.741715       0.042542            0.727672   \n",
      "1                0.494543         0.881343       0.828586            0.689760   \n",
      "2                0.195471         0.463179       0.249241            0.436059   \n",
      "3                0.736684         0.289076       0.283880            0.616270   \n",
      "4                0.418698         0.318761       0.226173            0.616760   \n",
      "\n",
      "   Infrastructure  Historical Floods  Flood Occurred  \n",
      "0             1.0                0.0             1.0  \n",
      "1             0.0                1.0             0.0  \n",
      "2             1.0                1.0             1.0  \n",
      "3             1.0                1.0             0.0  \n",
      "4             1.0                0.0             0.0  \n"
     ]
    }
   ],
   "source": [
    "# combine the flood_risk_dataset_india.csv combined_data_smote_10000_scaled.csv\n",
    "satellite_df = pd.read_csv('combined_data_smote_10000_scaled.csv')\n",
    "flood_risk_df = pd.read_csv('datasets/india_flood_risk/flood_risk_dataset_india.csv')\n",
    "\n",
    "# normalize and standardize the flood_risk_df\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# First, identify numerical columns for scaling (exclude non-numeric or identifier columns)\n",
    "# Assuming all columns except specific ones are numeric and need scaling\n",
    "numeric_cols = flood_risk_df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Create a copy of the dataframe to avoid modifying the original\n",
    "flood_risk_scaled_df = flood_risk_df.copy()\n",
    "\n",
    "# Apply standardization and normalization in one pipeline\n",
    "# Step 1: Standardize (z-score normalization)\n",
    "scaler = StandardScaler()\n",
    "flood_risk_standardized = scaler.fit_transform(flood_risk_df[numeric_cols])\n",
    "\n",
    "# Step 2: Apply MinMax scaling to the standardized data (normalize to [0,1] range)\n",
    "normalizer = MinMaxScaler()\n",
    "flood_risk_normalized = normalizer.fit_transform(flood_risk_standardized)\n",
    "\n",
    "# Replace the original numeric columns with the scaled values\n",
    "flood_risk_scaled_df[numeric_cols] = flood_risk_normalized\n",
    "\n",
    "# Display the result\n",
    "print(\"Original data (first 5 rows):\")\n",
    "print(flood_risk_df[numeric_cols].head())\n",
    "print(\"\\nNormalized and standardized data (first 5 rows):\")\n",
    "print(flood_risk_scaled_df[numeric_cols].head())\n",
    "\n",
    "# Save the preprocessed data if needed\n",
    "flood_risk_scaled_df.to_csv('flood_risk_dataset_india_scaled.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('combined_data_smote_10000_scaled.csv')\n",
    "\n",
    "# Map True to 1 and False to 0\n",
    "df['is_flood'] = df['is_flood'].map({True: 1, False: 0})\n",
    "\n",
    "# Save the modified dataframe to a new file\n",
    "# You can either save to a new file\n",
    "df.to_csv('combined_data_smote_10000_scaled_numeric.csv', index=False)\n",
    "\n",
    "# Or overwrite the existing file\n",
    "# df.to_csv('combined_data_smote_10000_scaled.csv', index=False)\n",
    "\n",
    "print(\"Conversion completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
